# ğŸ¤– GuÃ­a Completa: Agentes con LangChain + Ollama

## ğŸ“‹ Tabla de Contenidos
1. [IntroducciÃ³n](#introducciÃ³n)
2. [InstalaciÃ³n y ConfiguraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
3. [Â¿QuÃ© son los Agentes?](#quÃ©-son-los-agentes)
4. [Componentes de un Agente](#componentes-de-un-agente)
5. [Tipos de Agentes](#tipos-de-agentes)
6. [CÃ³mo Funcionan los Agentes](#cÃ³mo-funcionan-los-agentes)
7. [Herramientas (Tools)](#herramientas-tools)
8. [Memoria en Agentes](#memoria-en-agentes)
9. [Ejemplo PrÃ¡ctico](#ejemplo-prÃ¡ctico)
10. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ IntroducciÃ³n

Los **agentes** en LangChain son sistemas inteligentes que pueden:
- ğŸ§  **Razonar** sobre quÃ© acciones tomar
- ğŸ› ï¸ **Usar herramientas** para completar tareas
- ğŸ”„ **Iterar** hasta encontrar la respuesta correcta
- ğŸ’­ **Mantener memoria** de conversaciones anteriores

A diferencia de una simple llamada a un LLM, los agentes pueden decidir dinÃ¡micamente quÃ© herramientas usar y en quÃ© orden, basÃ¡ndose en el input del usuario.

---

## ğŸ”§ InstalaciÃ³n y ConfiguraciÃ³n

### Paso 1: Instalar Ollama

**En Windows:**
```bash
# Descarga el instalador desde https://ollama.com/download
# O usa winget:
winget install Ollama.Ollama
```

**En Linux/Mac:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### Paso 2: Descargar un Modelo

```bash
# Iniciar Ollama (si no estÃ¡ ejecutÃ¡ndose)
ollama serve

# En otra terminal, descargar un modelo
ollama pull llama2          # Modelo general (3.8GB)
# o
ollama pull mistral         # Alternativa mÃ¡s ligera (4.1GB)
# o
ollama pull llama3.2        # Ãšltimo modelo de Meta (2GB)
```

### Paso 3: Instalar Dependencias de Python

```bash
# Crear un entorno virtual (recomendado)
python -m venv venv

# Activar el entorno virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### Paso 4: Verificar la InstalaciÃ³n

```bash
# Verificar que Ollama estÃ¡ corriendo
ollama list  # Debe mostrar los modelos descargados

# Probar Ollama
ollama run llama2 "Hola, Â¿cÃ³mo estÃ¡s?"
```

---

## ğŸ¤” Â¿QuÃ© son los Agentes?

Un **agente** es un sistema que usa un LLM como motor de razonamiento para decidir quÃ© acciones tomar y en quÃ© orden.

### Diferencia: Chain vs Agent

| CaracterÃ­stica | Chain | Agent |
|----------------|-------|-------|
| **Flujo** | Predefinido y fijo | DinÃ¡mico y adaptativo |
| **Decisiones** | No toma decisiones | Decide quÃ© hacer en cada paso |
| **Herramientas** | Usa todas en orden fijo | Elige quÃ© herramientas usar |
| **Iteraciones** | Un solo paso | MÃºltiples iteraciones |

**Ejemplo de Chain:**
```
Usuario â†’ LLM â†’ BÃºsqueda Web â†’ LLM â†’ Respuesta
(siempre el mismo flujo)
```

**Ejemplo de Agent:**
```
Usuario: "Â¿CuÃ¡nto es 25Â°C en Fahrenheit multiplicado por 2?"

Agente piensa â†’ Usa ConvertidorTemperatura (25C)
             â†’ Observa resultado: 77Â°F
             â†’ Usa Calculadora (77*2)
             â†’ Observa resultado: 154
             â†’ Responde: "154"
```

---

## ğŸ§© Componentes de un Agente

### 1. **LLM (Large Language Model)**
El cerebro del agente. Razona sobre quÃ© hacer.

```python
from langchain_community.llms import Ollama

llm = Ollama(
    model="llama2",
    temperature=0.7  # Creatividad (0=determinista, 1=creativo)
)
```

### 2. **Herramientas (Tools)**
Capacidades que el agente puede usar.

```python
from langchain.agents import Tool

tool = Tool(
    name="Calculadora",
    func=calculadora,  # FunciÃ³n Python
    description="Para hacer cÃ¡lculos matemÃ¡ticos"
)
```

### 3. **Prompt Template**
Instrucciones de cÃ³mo debe razonar el agente.

```python
template = """Responde usando este formato:
Pregunta: {input}
Pensamiento: [quÃ© debo hacer]
AcciÃ³n: [herramienta a usar]
ObservaciÃ³n: [resultado]
Respuesta Final: [respuesta]"""
```

### 4. **Memoria (Opcional)**
Recordar conversaciones anteriores.

```python
from langchain.memory import ConversationBufferMemory

memoria = ConversationBufferMemory(
    memory_key="chat_history"
)
```

### 5. **Agent Executor**
Orquestador que ejecuta el ciclo del agente.

```python
from langchain.agents import AgentExecutor

executor = AgentExecutor(
    agent=agente,
    tools=herramientas,
    verbose=True  # Ver el proceso de razonamiento
)
```

---

## ğŸ­ Tipos de Agentes

### 1. **ReAct Agent** (Recomendado)
- **PatrÃ³n:** Reasoning + Acting
- **Ciclo:** Pensamiento â†’ AcciÃ³n â†’ ObservaciÃ³n â†’ Repetir
- **Uso:** Tareas generales con mÃºltiples herramientas

```python
from langchain.agents import create_react_agent

agente = create_react_agent(llm, tools, prompt)
```

### 2. **Zero-shot ReAct**
- Similar a ReAct pero sin ejemplos previos
- MÃ¡s simple, menos contexto

### 3. **Conversational Agent**
- Optimizado para conversaciones
- Mantiene mejor el contexto del chat

### 4. **Structured Chat Agent**
- Para herramientas con inputs complejos (JSON, etc.)

### 5. **OpenAI Functions Agent**
- Usa function calling de OpenAI
- No compatible con Ollama (requiere OpenAI API)

---

## âš™ï¸ CÃ³mo Funcionan los Agentes

### Ciclo de EjecuciÃ³n (ReAct Pattern)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. USUARIO: "Â¿CuÃ¡nto es 15 * 8?"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. AGENTE PIENSA:                       â”‚
â”‚     "Necesito calcular 15 * 8"           â”‚
â”‚     "Tengo una herramienta Calculadora"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. AGENTE DECIDE:                       â”‚
â”‚     AcciÃ³n: Calculadora                  â”‚
â”‚     Input: "15 * 8"                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. EJECUTA HERRAMIENTA:                 â”‚
â”‚     calculadora("15 * 8")                â”‚
â”‚     â†’ Resultado: 120                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. OBSERVACIÃ“N:                         â”‚
â”‚     "El resultado es 120"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. AGENTE PIENSA:                       â”‚
â”‚     "Ya tengo la respuesta"              â”‚
â”‚     "No necesito mÃ¡s herramientas"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. RESPUESTA FINAL:                     â”‚
â”‚     "15 multiplicado por 8 es 120"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ejemplo de Salida Verbose

Cuando ejecutas con `verbose=True`, ves:

```
> Entering new AgentExecutor chain...
Pregunta: Â¿CuÃ¡nto es 15 * 8?
Pensamiento: Necesito hacer un cÃ¡lculo matemÃ¡tico
AcciÃ³n: Calculadora
Entrada de AcciÃ³n: 15 * 8
ObservaciÃ³n: El resultado es: 120
Pensamiento: Ahora sÃ© la respuesta final
Respuesta Final: 15 multiplicado por 8 es 120

> Finished chain.
```

---

## ğŸ› ï¸ Herramientas (Tools)

### AnatomÃ­a de una Herramienta

```python
from langchain.agents import Tool

def mi_funcion(input_texto: str) -> str:
    """DescripciÃ³n de lo que hace la funciÃ³n"""
    # LÃ³gica aquÃ­
    return "resultado"

herramienta = Tool(
    name="NombreCorto",  # Sin espacios, camelCase
    func=mi_funcion,     # La funciÃ³n Python
    description="DescripciÃ³n CLARA de cuÃ¡ndo usarla"  # Â¡MUY IMPORTANTE!
)
```

### âš ï¸ La DescripciÃ³n es CRÃTICA

El agente decide quÃ© herramienta usar basÃ¡ndose **solo en la descripciÃ³n**. Debe ser:
- âœ… Clara y especÃ­fica
- âœ… Indicar quÃ© tipo de input espera
- âœ… Indicar quÃ© devuelve
- âŒ No ambigua
- âŒ No vaga

**Ejemplo MALO:**
```python
description="Una herramienta Ãºtil"  # ğŸš« Demasiado vaga
```

**Ejemplo BUENO:**
```python
description="Convierte temperaturas entre Celsius y Fahrenheit. Input: '25C' o '77F'"  # âœ…
```

### Tipos de Herramientas Comunes

#### 1. Herramientas de CÃ¡lculo
```python
def calculadora(expresion: str) -> str:
    resultado = eval(expresion)  # âš ï¸ Sanitizar en producciÃ³n!
    return str(resultado)
```

#### 2. Herramientas de BÃºsqueda
```python
from langchain.tools import DuckDuckGoSearchRun

search = DuckDuckGoSearchRun()
```

#### 3. Herramientas de Base de Datos
```python
from langchain.tools import QuerySQLDataBaseTool

db_tool = QuerySQLDataBaseTool(db=db)
```

#### 4. Herramientas Personalizadas
```python
@tool
def obtener_clima(ciudad: str) -> str:
    """Obtiene el clima actual de una ciudad"""
    # Llamada a API del clima
    return f"Clima en {ciudad}: 22Â°C, soleado"
```

---

## ğŸ’¾ Memoria en Agentes

### Tipos de Memoria

#### 1. **ConversationBufferMemory**
Guarda todo el historial.

```python
from langchain.memory import ConversationBufferMemory

memoria = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)
```

**Ventajas:** Contexto completo
**Desventajas:** Crece indefinidamente

#### 2. **ConversationBufferWindowMemory**
Solo las Ãºltimas N interacciones.

```python
from langchain.memory import ConversationBufferWindowMemory

memoria = ConversationBufferWindowMemory(
    k=5,  # Ãšltimas 5 interacciones
    memory_key="chat_history"
)
```

**Ventajas:** TamaÃ±o limitado
**Desventajas:** Pierde contexto antiguo

#### 3. **ConversationSummaryMemory**
Resume conversaciones antiguas.

```python
from langchain.memory import ConversationSummaryMemory

memoria = ConversationSummaryMemory(
    llm=llm,
    memory_key="chat_history"
)
```

**Ventajas:** Mantiene contexto sin crecer mucho
**Desventajas:** Requiere llamadas extra al LLM

---

## ğŸ“ Ejemplo PrÃ¡ctico

### Caso de Uso: Asistente de AnÃ¡lisis de Datos

```python
from langchain_community.llms import Ollama
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
import pandas as pd

# 1. Herramienta para leer CSV
def leer_csv(archivo: str) -> str:
    """Lee un archivo CSV y devuelve info bÃ¡sica"""
    df = pd.read_csv(archivo)
    return f"Filas: {len(df)}, Columnas: {list(df.columns)}"

# 2. Herramienta para estadÃ­sticas
def estadisticas(columna: str) -> str:
    """Calcula estadÃ­sticas de una columna"""
    # Asumiendo df global
    stats = df[columna].describe()
    return str(stats)

# 3. Crear herramientas
tools = [
    Tool(name="LeerCSV", func=leer_csv,
         description="Lee CSV. Input: ruta del archivo"),
    Tool(name="Stats", func=estadisticas,
         description="EstadÃ­sticas de columna. Input: nombre columna")
]

# 4. Configurar agente
llm = Ollama(model="llama2")
prompt = PromptTemplate(...)  # Template ReAct
agente = create_react_agent(llm, tools, prompt)
executor = AgentExecutor(agent=agente, tools=tools, verbose=True)

# 5. Usar
executor.invoke({"input": "Analiza el archivo ventas.csv"})
```

---

## ğŸ› Troubleshooting

### âŒ Error: "Connection refused"

**Problema:** Ollama no estÃ¡ ejecutÃ¡ndose.

**SoluciÃ³n:**
```bash
ollama serve
```

### âŒ Error: "Model not found"

**Problema:** El modelo no estÃ¡ descargado.

**SoluciÃ³n:**
```bash
ollama pull llama2
```

### âŒ El agente no usa las herramientas correctamente

**Problema:** DescripciÃ³n de herramientas poco clara.

**SoluciÃ³n:**
- Mejorar las descripciones
- AÃ±adir ejemplos de input en la descripciÃ³n
- Usar un modelo mÃ¡s potente (llama3 > llama2)

### âŒ El agente entra en bucle infinito

**Problema:** No puede decidir quÃ© hacer.

**SoluciÃ³n:**
```python
AgentExecutor(
    agent=agente,
    tools=tools,
    max_iterations=5,  # Limitar iteraciones
    handle_parsing_errors=True  # Manejar errores de parsing
)
```

### âŒ Respuestas muy lentas

**Problema:** Ollama procesando en CPU.

**SoluciÃ³n:**
- Usar un modelo mÃ¡s pequeÃ±o (llama3.2 en lugar de llama2)
- Si tienes GPU NVIDIA, Ollama la usarÃ¡ automÃ¡ticamente
- Reducir `max_iterations`

---

## ğŸš€ Mejores PrÃ¡cticas

### 1. DiseÃ±o de Herramientas
- âœ… Una herramienta = una responsabilidad
- âœ… Descripciones ultra-claras
- âœ… Manejo de errores robusto
- âœ… ValidaciÃ³n de inputs

### 2. Prompts
- âœ… Usar ejemplos en el prompt (few-shot)
- âœ… Ser explÃ­cito sobre el formato esperado
- âœ… Indicar cuÃ¡ndo responder directamente vs usar herramientas

### 3. OptimizaciÃ³n
- âœ… Limitar `max_iterations` (evitar bucles infinitos)
- âœ… Usar `verbose=True` durante desarrollo
- âœ… Cachear resultados cuando sea posible
- âœ… Usar memoria window en lugar de buffer completo

### 4. Seguridad
- âš ï¸ NUNCA uses `eval()` sin sanitizar
- âš ï¸ Valida inputs de usuario
- âš ï¸ Limita recursos (tiempo, memoria)
- âš ï¸ No expongas informaciÃ³n sensible en las descripciones

---

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n Oficial
- [LangChain Agents](https://python.langchain.com/docs/modules/agents/)
- [Ollama](https://ollama.com/)

### Modelos Recomendados para Agentes
- **llama3.2** (2GB) - MÃ¡s reciente, buen balance
- **mistral** (4.1GB) - Muy bueno para razonamiento
- **llama2** (3.8GB) - ClÃ¡sico, estable
- **codellama** (3.8GB) - Para tareas de cÃ³digo

### Comandos Ãštiles de Ollama
```bash
ollama list                    # Listar modelos instalados
ollama pull <modelo>           # Descargar modelo
ollama rm <modelo>             # Eliminar modelo
ollama show <modelo>           # Info del modelo
ollama run <modelo> "prompt"   # Probar modelo
```

---

## ğŸ“ Ejercicios Propuestos

1. **BÃ¡sico:** AÃ±ade una herramienta que calcule el IMC (peso/alturaÂ²)

2. **Intermedio:** Crea un agente que pueda leer archivos, buscar palabras y contar ocurrencias

3. **Avanzado:** Implementa un agente con acceso a SQLite que pueda crear tablas, insertar datos y hacer queries

---

## ğŸ“ Soporte

Si tienes problemas:
1. Revisa que Ollama estÃ© ejecutÃ¡ndose: `ollama list`
2. Verifica las versiones: `pip list | grep langchain`
3. Prueba con `verbose=True` para ver quÃ© estÃ¡ pasando
4. Revisa los logs de Ollama

---

**Â¡Buena suerte creando agentes! ğŸš€**
